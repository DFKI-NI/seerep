{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"data-protection-notice/","title":"Data Protection Notice","text":"<p>The German Research Center for Artificial Intelligence (Deutsches Forschungszentrum f\u00fcr K\u00fcnstliche Intelligenz GmbH (DFKI)) and its staff are committed to goal- and risk-oriented information privacy and the fundamental right to the protection of personal data. In this data protection policy we inform you about the processing of your personal data when visiting and using our web site.</p>"},{"location":"data-protection-notice/#controller","title":"Controller","text":"<p>Deutsches Forschungszentrum f\u00fcr K\u00fcnstliche Intelligenz GmbH (DFKI) Phone: +49 631 20575 0 info@dfki.de Legal Notice</p>"},{"location":"data-protection-notice/#data-protection-officer","title":"Data protection officer","text":"<p>Phone: +49 631 20575 0 datenschutz@dfki.de</p>"},{"location":"data-protection-notice/#hosting-server","title":"Hosting Server","text":"<p>This website is hosted with Github. For more information about github's data processing and contacts, please refer to the Privacy Policy.</p>"},{"location":"data-protection-notice/#access-and-intervention","title":"Access and Intervention","text":"<p>Besides the information in this data protection policy you have the right of access to your personal data. To ensure fair data processing, you have the following rights:</p> <ul> <li>The right to rectification and completion of your personal data</li> <li>The right to erasure of your personal data</li> <li>The right to restriction of the processing of your personal data</li> <li>The right to object to the processing of your personal data on grounds related   to your particular situation</li> </ul> <p>To exercise these rights, please contact our data protection officer.</p>"},{"location":"data-protection-notice/#right-to-lodge-a-complaint","title":"Right to lodge a complaint","text":"<p>You have the right to lodge a complaint with a supervisory authority if you consider that the processing of your personal data infringes statutory data protection regulations.</p>"},{"location":"legal-notice/","title":"LEGAL NOTICE","text":""},{"location":"legal-notice/#responsible-service-provider","title":"Responsible service provider","text":"<p>Responsible for the content of the domain agri-gaia.github.io/seerep from the point of view of \u00a7 5 TMG:</p> <p>Deutsches Forschungszentrum f\u00fcr K\u00fcnstliche Intelligenz GmbH (DFKI) Management: Prof. Dr. Antonio Kr\u00fcger Helmut Ditzer Trippstadter Str. 122 67663 Kaiserslautern Germany</p> <p>Phone: +49 631 20575 0 Email: info@dfki.de</p> <p>Register Court: Amtsgericht Kaiserslautern Register Number: HRB 2313</p> <p>ID-Number: DE 148 646 973</p> <p>The person responsible for the editorial content of the domain agri-gaia.github.io/seerep of the German Research Center for Artificial Intelligence GmbH within the meaning of \u00a7 18 para. 2 MStV is:</p> <p>Mark Niemeyer Hamburger Stra\u00dfe 24 49084 Osnabr\u00fcck Germany</p> <p>Phone: +49 541 386050 2254 E-mail: mark.niemeyer@dfki.de Website URL:"},{"location":"legal-notice/#liability-for-content","title":"Liability for content","text":"<p>As a service provider, Deutsches Forschungszentrum f\u00fcr K\u00fcnstliche Intelligenz GmbH (DFKI) is responsible under general law for its own content published on this website in accordance with Section 7 para. 1 of the German Telemedia Act (TMG).</p> <p>DFKI makes every effort to keep the information on our website accurate and current, nevertheless, errors and uncertainties cannot be entirely ruled out. For this reason, DFKI undertakes no liability for ensuring that the provided information is current, accurate or complete, and is not responsible for its quality. DFKI is not liable for material or immaterial damages caused directly or indirectly by the use or non-use of the offered information, or by the use of erroneous and incomplete information, unless willful or grossly negligent fault can be demonstrated. This also applies with respect to software or data provided for download.</p> <p>DFKI reserves the right to modify, expand or delete parts of the website or the entire website without separate announcement, or to cease publication temporarily or definitively.</p>"},{"location":"legal-notice/#liability-for-links","title":"Liability for links","text":"<p>Pursuant to Section 7 para. 1 of TMG (German Tele-Media Act), the law limits our responsibility as a service provider to our own content on this website. According to Sections 8 \u2013 10 TMG, we are not obliged to permanently monitor any transmitted or stored third-party information, nor to investigate circumstances that might indicate illegal activity. This does not affect our obligation to remove or block information according to general law. However, we can only assume liability for such data from the point in time at which a concrete legal infringement has been identified. Upon notification of any such legal infringement, we will immediately delete the infringing content.</p> <p>Cross-references (\u201clinks\u201d) to the content providers are to be distinguished from our own content. Our offer includes links to external third-party websites. Providers or operators of linked external pages are always responsible for their respective content. We cannot assume any liability for the content of the linked pages. This third-party content was checked by DFKI when the links were first set up to determine whether any legal infringements existed. At the time of the check, no legal infringements were apparent. However, it cannot be ruled out that the content is subsequently changed by the respective providers. A permanent control of the content of the linked pages is not reasonable without evidence of a legal infringement. Should you believe that the linked external pages infringe applicable law or otherwise contain inappropriate content, please notify us directly at: info@dfki.de.</p> <p>In case DFKI should notice or receive any indication that an external offer to which it has linked might cause civil or criminal liability, DFKI will immediately delete this link.</p>"},{"location":"legal-notice/#copyright","title":"Copyright","text":"<p>The layout of the homepage, the graphics used and other content on the DFKI website are protected by copyright. The reproduction, processing, distribution and any type of use outside the boundaries of copyright law require the prior written approval of the DFKI. Insofar as any content on this page was not reated by DFKI, the copyrights of third parties will be respected. If you believe that you discovered a copyright infringement, please report this to us accordingly. Upon becoming aware of any legal infringements, DFKI will remove or disable access to such infringing content immediately.</p>"},{"location":"getting-started/dev_setup/","title":"Development Setup","text":"<p>For the development of SEEREP, a Visual Studio Code Dev Container is used. This enables the use of a Docker container as a development environment, handling dependencies in a unified manner and abstracting different operating systems. For the system requirements, please refer to the Visual Studio Code Docs.</p>"},{"location":"getting-started/dev_setup/#setup","title":"Setup","text":"<p>Clone the repository with:</p> sshhttps <pre><code>git clone git@github.com:agri-gaia/seerep.git\n</code></pre> <pre><code>git clone https://github.com/agri-gaia/seerep\n</code></pre> <p>For the development, it is assumed that the directory designated for SEEREP's data storage is a sibling folder named <code>seerep-data</code>, located next to the repository. Make sure it exists!</p> <pre><code>mkdir seerep-data\n</code></pre> <p>Warning</p> <p>Since a Docker bind mount is used to mount the data storage directory inside the container, providing an incorrect or non-existent path for the host directory will result in an unclear error message when starting the container.</p> <p>Subsequently, install the Remote Containers and Docker Visual Studio Code extensions:</p> <pre><code>code --install-extension ms-vscode-remote.remote-containers ; \\\ncode --install-extension ms-azuretools.vscode-docker\n</code></pre> <p>Launch Visual Studio Code within the repository:</p> <pre><code>code seerep\n</code></pre> <p>The presence of a <code>.devcontainer</code> folder should automatically trigger the detection of a Dev-Container environment. To reopen the repository folder in the container, a prompt will appear on the lower right corner:</p> <p> </p>  Reopen in Dev-Container menu  <p>Or in case this window doesn't open, use either F1 or Ctrl+Shift+P and input <code>Remote-Containers: Reopen Folder in Container</code>. Confirm by pressing Enter.</p> <p>Starting the Dev-Container the first time may take a while as it involves downloading the required SEEREP Docker image (around 4 GB). Additionally Visual Studio Code extensions, Intellisense, and pre-commit checks are setup in the container.</p>"},{"location":"getting-started/dev_setup/#container-credentials","title":"Container Credentials","text":"<p>The default credentials have both the username and password set to <code>docker</code>.</p>"},{"location":"getting-started/dev_setup/#pre-commit-checks","title":"Pre Commit Checks","text":"<p>The repository uses pre-commit hooks to verify compliance with established coding guidelines and, if necessary, to format the code in a consistent way. The checks are automatically run before each commit and as part of the GitHub CI. To manually run the checks use:</p> <pre><code>pre-commit run -a\n</code></pre> <p>The main hooks are:</p> <ul> <li>Clang-Format 15 for C/C++</li> <li>Ruff for Python</li> <li>Markdownlint for Markdown</li> </ul> <p>Along with other checks for Dockerfiles and YAML, see the complete list in the configuration.</p>"},{"location":"getting-started/dev_setup/#debugging-with-vs-code","title":"Debugging with VS-Code","text":"<p>Inside the Dev-Container, <code>catkin</code> builds the server executable in debug mode by default. To start debugging with VS-Code support, the provided launch configurations can be used. For that switch into the <code>Run and Debug</code> window (Ctrl+Shift+D ) and select <code>seerep_server</code>from the dropdown. To finally launch the server, click the  button.</p> <p> </p>  Start SEEREP in debug mode inside VS-Code  <p>The <code>gdb</code> debug console should be displayed at the bottom. Switching to the terminal tab provides access to the logging output. An example from a fresh server start is shown below:</p> <p> </p>  Terminal output upon start  <p>For further information regarding debugging in VS-Code check the offical docs.</p>"},{"location":"getting-started/docs/","title":"Documentation Setup","text":"<p>The documentation is divided into two main parts: MkDocs is used for general documentation and Doxygen is used for C++ code documentation.</p>"},{"location":"getting-started/docs/#dependencies","title":"Dependencies","text":"<p>Installing the dependencies in the following sections is only ncessaary if you are not using the VS-Code Development Container.</p>"},{"location":"getting-started/docs/#mkdocs","title":"MkDocs","text":"<p>To install the Python dependencies, navigate to the repository's main folder and run:</p> <pre><code>pip3 install -r docker/base/requirements.docs.txt\n</code></pre> <p>To build and deploy MkDocs locally use:</p> <pre><code># ensure that the mkdocs.yaml is located in the directory\nmkdocs serve\n</code></pre> <p>The page should then be available under http://127.0.0.1:8000/. Live reloading is enabled, saved changes are automatically updated.</p>"},{"location":"getting-started/docs/#doxygen","title":"Doxygen","text":"<p>To install a recent version of Doxygen, it is necessary to build it from source:</p> <pre><code>sudo apt install flex bison make\\\n    &amp;&amp; export DOX_VER=\"Release_1_9_3\"\\\n    &amp;&amp; wget https://github.com/doxygen/doxygen/archive/refs/tags/${DOX_VER}.tar.gz\\\n    &amp;&amp; tar -xf ${DOX_VER}.tar.gz\\\n    &amp;&amp; mkdir -p doxygen-${DOX_VER}/build\\\n    &amp;&amp; cd doxygen-${DOX_VER}/build\\\n    &amp;&amp; cmake -G \"Unix Makefiles\" ..\\\n    &amp;&amp; make -j\"$(nproc)\"\\\n    &amp;&amp; sudo make install\\\n    &amp;&amp; cd ../..\\\n    &amp;&amp; rm -rf doxygen-${DOX_VER} ${DOX_VER}.tar.gz\\\n    &amp;&amp; unset DOX_VER\n</code></pre> <p>To generate the Doxygen documentation, run the following command in the repository's main directory:</p> <pre><code>doxygen Doxyfile\n</code></pre> <p>To start a local web server to serve the content use:</p> <pre><code>cd doxygen-output/html/\npython3 -m http.server\n</code></pre> <p>The page should be accessible at the default http://0.0.0.0:8000/. If you want to run both MkDocs and Doxygen simultaneously, you need to assign a different port to the HTTP server for Doxygen, for example by using:</p> <pre><code>python3 -m http.server 9000\n</code></pre>"},{"location":"getting-started/docs/#github-pages-deployment","title":"GitHub Pages Deployment","text":"<p>Both documentation pages are automatically deployed to GitHub Pages through a workflow. A new version is released after a pull request to the main branch. Publishing both documentations requires a workaround, as a repository typically only supports one URL. The main page is a simple HTML document that links to the individual pages:</p> index.html<pre><code>&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n\n&lt;head&gt;\n  &lt;meta charset=\"UTF-8\"&gt;\n  &lt;title&gt;SEEREP-Documentation&lt;/title&gt;\n&lt;/head&gt;\n\n&lt;body&gt;\n  &lt;ul&gt;\n    &lt;li&gt;&lt;a href=\"mkdocs/home/index.html\"&gt;MkDocs &lt;/a&gt;&lt;/li&gt;\n    &lt;li&gt;&lt;a href=\"doxygen/index.html\"&gt;Doxygen&lt;/a&gt;&lt;/li&gt;\n    &lt;li&gt;&lt;a href=\"mkdocs/legal-notice/index.html\"&gt;Legal Notice &lt;/a&gt;&lt;/li&gt;\n    &lt;li&gt;&lt;a href=\"mkdocs/data-protection-notice/index.html\"&gt;Data Protection Notice &lt;/a&gt;&lt;/li&gt;\n  &lt;/ul&gt;\n&lt;/body&gt;\n\n&lt;/html&gt;\n</code></pre>"},{"location":"getting-started/grpc_clients/","title":"gRPC Clients","text":""},{"location":"getting-started/grpc_clients/#python-api","title":"Python API","text":"<p>The gRPC API of SEEREP is bundeled as a Python package and is available as <code>seerep-grpc</code> on PyPi. To install use:</p> <pre><code>pip3 install seerep-grpc\n</code></pre>"},{"location":"getting-started/grpc_clients/#package-structure","title":"Package Structure","text":"<p>The package contains the Python bindings generated by the <code>protoc</code> (Protocol Buffers) and <code>flatc</code> (Flatbuffers) compilers as well as general wrappers and helper functions. The package is structured as follows:</p> <pre><code>seerep/\n  fb/\n    *.py # flatbuffer msgs and interfaces\n  pb/\n    *.py # protocl buffer msgs and interfaces\n  util/\n    common.py # general helpers e.g setting up a grpc connection\n    fb_helper.py # wrappers to create flatbuffer messages more easily\n    visualizations.py # visualizations\n</code></pre> <p>Importing from the modules can be done like this:</p> <pre><code>from seerep.pb import image_pb2 as image\nfrom seerep.pb import image_service_pb2_grpc as image_service_fb\n</code></pre> <pre><code>from seerep.fb import Image\nfrom seerep.fb import image_service_grpc_fb as image_service_pb\n</code></pre> <p>For more advanced examples have a look at the examples section.</p>"},{"location":"getting-started/grpc_clients/#building-locally","title":"Building Locally","text":"<p>To build the package locally e.g. to distribute recent changes from a branch use:</p> <pre><code>python3 -m build\n</code></pre> <p>in the main repository directory. There now should be a <code>dist</code> directory which contains the wheel files (<code>*.whl</code>) and the archived source files.</p> <p>Within the Dev-Container, the package building process is integrated into the CMake workflow, such that running:</p> <pre><code>catkin build # generally works but takes a bit longer\ncatkin build seerep_msgs # update on the messages\ncatkin build seerep_com # update on the interface\n</code></pre> <p>is required, to see the changes reflected</p>"},{"location":"getting-started/grpc_clients/#releasing-a-new-version","title":"Releasing a New Version","text":"<p>A new version of the package is automatically released whenever there is a new SEEREP release, using the main workflow.</p>"},{"location":"getting-started/grpc_clients/#c-api","title":"C++ API","text":"<p>The C++ bindings for the interfaces and messages are also generated within the Dev-Container and can be included in other packages using standard CMake methods. As an example use the <code>examples_cpp</code> package from the repository.</p>"},{"location":"getting-started/known_issues/","title":"Known Issues","text":"<p>This page serves as a list of fixes or workarounds for common errors encountered while developing SEEREP. If you find a fix that isn't included, please consider adding it.</p>"},{"location":"getting-started/known_issues/#starting-the-dev-container-fails","title":"Starting the Dev-Container Fails","text":"<p>If the automatic contianer setup or the <code>Remote-Containers: Reopen Folder in Container</code> fails, one of the following steps may resolve it:</p> <ol> <li> <p>Make sure that the container is not running in the backgound:</p> <pre><code>docker stop $(docker ps | grep seerep | awk '{print $1}')\n</code></pre> </li> <li> <p>Often, a fresh install can fix problems. Use the following commands to delete everything regarding SEEREP from Docker:</p> <pre><code># remove container\ndocker rm $(docker container ls -a | grep seerep | awk '{print $1}')\n# remove images\ndocker rmi $(docker image ls -a | grep seerep | awk '{print $1}')\n# remove volumes\ndocker volume rm seerep-vscode-extensions vscode\n</code></pre> </li> </ol>"},{"location":"getting-started/known_issues/#running-out-of-ram-when-compiling","title":"Running out of RAM when Compiling","text":"<p>When compiling and linking the server executable (especially when using WSL) catkin may allocate more than 13 GB of system memory. To restrict the memory usage of <code>catkin</code> use:</p> <pre><code>pip3 install psutil\n# relative to the full system memory\ncatkin build --mem-limit 40%\n# absolute maximum of system memory to use\ncatkin build --mem-limit 8G\n</code></pre> <p>For more details, refer to the catkin documentation.</p>"},{"location":"getting-started/known_issues/#macos-false-positives-by-check-executables-have-shebangs","title":"[MacOS] False Positives by Check-Executables-Have-Shebangs","text":"<p>Due to a bug in Docker for MacOS non-executables get falsely reported as executables see pre-commit/pre-commit-hooks#528 and the corresponding upstream bug docker/for-mac#5029. The current workaround is to change the file system implementation to the noticably slower <code>osxfs</code>in the Docker Desktop settings (both <code>VirtioFS</code> and <code>gRPC FUSE</code> have the bug in version <code>4.31.0</code>). If there are no other pre-commit violations, commit without checks using <code>git commmit --no-verify -m \"message\"</code>.</p>"},{"location":"getting-started/server_deployment/","title":"Server Deployment","text":""},{"location":"getting-started/server_deployment/#docker","title":"Docker","text":"<p>The easiest way to start a production instance of SEEREP is with <code>docker compose</code>, using the corresponding file in the <code>docker/server</code> directory:</p> <pre><code>cd docker/server\ndocker compose up\n</code></pre> <p>Use of named Docker volumes</p> <p> Compared to the Dev-Container, the production setup uses named Docker volumes. Which do not require any specific directory on the host system. The volumes also keeps the data between restarts.     For an empty server delete the volumes with <code>docker volume rm seerep_log seerep_data</code>.</p> <p>Configuration of the compose setup is done through the <code>.env</code> file located in the same directory. For details on the individual options, refer to the configuration section.</p> <p>A closer look at the Docker compose file might lead to questions about the extra service, that adjusts the owner of the log and data directories. The main reason for this is that named volumes are created with root permissions when the mount location does not exist. However since the container is run as non-root for security reasons (as should ever other container), we are not able to change the permissions without hard-coding the mount locations in the Dockerfile. To change the permissions, a very small container mounts the volumes and changes the permission to the specified <code>uid</code> and <code>guid</code> after which SEEREP is started with the same user. Additional information can be found in the PR#376 discussion.</p>"},{"location":"getting-started/server_deployment/#kubernetes","title":"Kubernetes","text":"<p>Not actively maintained!</p> <p> The deployment of SEEREP using Kubernetes is currently not actively maintained.</p>"},{"location":"getting-started/server_deployment/#relevant-files","title":"Relevant files","text":"<p>Seerep can either be installed with the latest development state or the latest stable version. The relevant files can be found under:</p> <pre><code>/docker/kustomize/base --&gt; development\n/docker/kustomize/overlays/production --&gt; latest stable release\n</code></pre> <p>The base-folder contains all yaml-files for a cluster deployment. This includes:</p> <ul> <li>Deployment</li> <li>PersistentVolume (PV) and PersistentVolumeClaim (PVC)</li> <li>Service</li> <li>Ingress</li> <li>Configuration</li> </ul> <p>The yaml-file for the cluster is create via Kustomize, hence this folder also contains a kustomization.yaml which puts everything together.</p> <p>The <code>/overlay/production</code> directory contains a second <code>kustomization.yaml</code>. Within this file everything needed to install a production system is overridden. This means, that the sealed secret is replaced with a new one, while the base secret is deleted. Further, the labels and the names of PV and PVC are changed to create new storage explicitly for the production system. Finally, the used image is replaced with the latest stable release.</p> <p>The usage of an overlay, thereby, follows the principles of Kustomize.</p>"},{"location":"getting-started/server_deployment/#building-with-kustomize","title":"Building with Kustomize","text":"<p>Kustomize needs to be installed before building the Kubernetes manifest (Kustomize installation). The easiest way to do that is to download the latest binary from the offical release page.</p> <p>To install the base version of SEEREP, one can either run:</p> <pre><code>kustomize build base/ &gt; seerep-deployment.yaml\n</code></pre> <p>to store the manifest in a separate <code>.yaml</code> file. Or directly use kubectl:</p> <pre><code>kubectl apply -k base/\n</code></pre> <p>In order to install the production version, the commands look slightly different:</p> <pre><code>kustomize build overlays/production/ &gt; seerep-deployment.yaml\n</code></pre> <pre><code>kubectl apply -k overlays/production/\n</code></pre> <p>If a ArgoCD instance is available, SEEREP can also be added as a project.</p>"},{"location":"getting-started/server_deployment/#sealed-secrets","title":"Sealed Secrets","text":"<p>The certificates used for the secured ingress are created as a sealed-secret. Hence, the secret can safely be stored in a repository. The sealed secret controller installed within the cluster will take care of unsealing the secret and make it usable. To combine Kustomize and sealed secrets this blogs-post was followed faun.pub.</p>"},{"location":"getting-started/server_deployment/#configuration","title":"Configuration","text":"<p>SEEREP can be configured in three different ways: via command line arguments, a config file, or environment variables.</p>"},{"location":"getting-started/server_deployment/#command-line","title":"Command line","text":"<p>To get a full list of all arguments use <code>--help</code>:</p> <pre><code>Allowed options:\n\nGeneric options:\n  -v [ --version ]                      Get a version string\n  --help                                Help message\n  -c [ --config ] arg                   Path to a configuration file\n\nConfiguration:\n  -D [ --data-folder ] arg (=/seerep/src)\n                                        Data storage folder\n  -L [ --log-path ] arg (=/seerep/src)  Path to store the logs\n  --log-level arg (=info)               log-level [trace, debug, info, warning,\n                                        error, fatal]\n  -p [ --port ] arg (=9090)             gRPC port to use\n</code></pre> <p>The configuration parameters are provided with default values (shown in parentheses).</p>"},{"location":"getting-started/server_deployment/#config-file","title":"Config file","text":"<p>The command line options can also be set through a config file:</p> <pre><code>$(which seerep_server) --config seerep.cfg\n</code></pre> <p>An example config file is shown below:</p> seerep.cfg<pre><code>data-folder = /seerep/seerep-data/ #defaulting to work dir\nlog-path = /seerep/seerep-data/log/ #file logging disabled if not set\nlog-level = info\n#port = 9090\n</code></pre>"},{"location":"getting-started/server_deployment/#environment-variables","title":"Environment Variables","text":"<p>Additionally, SEEREP can be configured using environment variables, which correspond to the command line arguments as follows:</p> Environment variable Command Line SEEREP_DATA_FOLDER --data-folder SEEREP_LOG_PATH --log-path SEEREP_LOG_LEVEL --log-level SEEREP_PORT --port"},{"location":"getting-started/tests/","title":"Tests","text":"<p>SEEREP uses GoogleTest for C++ Unit Tests and pytest for integration tests. Unit tests are placed into the individual ROS packages while the intregation tests are setup in the <code>/test</code> directory. The tests run automatically as a GitHub Action with every push.</p>"},{"location":"getting-started/tests/#c-unit-tests","title":"C++ Unit Tests","text":"<p>Currently unit tests are set up for:</p> <ul> <li>Flatbuffer ROS Conversions:     Functions for converting ROS message to Flatbuffers message and vice versa.</li> <li>HDF5 PB Image Interface     : Reading and writing of Protocol Buffer image messages to HDF5.</li> <li>HDF5 FB Image Interface     : Reading and writing of Flatbuffer image messages to HDF5.</li> </ul>"},{"location":"getting-started/tests/#using-catkin","title":"Using catkin","text":"<p>To run the tests with <code>catkin</code> use:</p> <pre><code>catkin test # run all availabe tests\ncatkin test &lt;specific-package&gt; # run all tests from a specific package\n</code></pre>"},{"location":"getting-started/tests/#python-integration-tests","title":"Python Integration Tests","text":"<p>The integration tests, based on the Python examples, cover most of the send and receive operations of SEEREP.</p>"},{"location":"getting-started/tests/#using-pytest","title":"Using pytest","text":"<p>To run all integration tests use:</p> <pre><code>pytest\n</code></pre> <p>in the main repository directory.</p> <p>To execute a subset of the integration tests use:</p> <pre><code># Recursively executes all tests in the meta directory\npytest tests/python/gRPC/meta\n\n# Same execution as above\ncd tests/python/gRPC/meta\npytest\n\n# Run all tests specified in this file\npytest tests/python/gRPC/meta/test_gRPC_pb_projectCreation.py\n</code></pre>"},{"location":"getting-started/tests/#testing-through-vscode","title":"Testing through VSCode","text":"<p>Another way to run the tests is through the VSCode Testing Tab ( icon)</p> <p>Info</p> <p> With a fresh installation of the project, the test cases might not be recognized. To resolve this, use the  button in the top menu to refresh.</p> <p>To run the tests use the  button at the top or select individual test cases to run.</p> <p> </p>  Sucessfull run all of tests using the VS-Code test explorer"},{"location":"home/","title":"Home","text":"<p>The objective of SEEREP (SEmantic Environment REPresentation) is to store generated robot data and enable fast spatio-temporal-semantic queries over the data.</p>"},{"location":"home/#context","title":"Context","text":"<p>Autonomous robotic systems must be aware of their environment, in order to safely achieve their goal-oriented actions. Especially in unstructured and changing environments, a detailed model of the environment is required for reasoning and planning.</p> <p>The sensors of a robot provide spatial information via the robot's pose, temporal information is created by the point in time when a sensor is read. Semantic information always exists implicitly and can be made explicit by algorithms or manual labeling.</p> <p>Most existing environment representations focus on one or two of these information types, SEEREP is able to store all three. Thereby, SEEREP enables the robot to reason on a higher level and disambiguate sensor data based on the context.</p>"},{"location":"home/#core-features","title":"Core Features","text":"<ul> <li>Store robotic sensor data</li> <li>Images</li> <li>3D-Points</li> <li>Point Clouds</li> <li>TF</li> <li>Store analysis results alongside the corresponding sensor data</li> <li>Add (bounding box based) semantic annotations with confidences to the data</li> <li>Extend semantic annotations by object instances which are in multiple datasets</li> <li>Store information about an instance alongside the data</li> <li>Link 3d points to an instance to define the instance position</li> <li>Allow multiple categories of labels (e.g. a category per CNN). Thus, enabling     easy evaluation and comparison of   multiple CNNs based on the same data</li> <li>Fast spatio-temporal-semantic queries with   gRPC.</li> <li>Storage of data generated by the robotic system:</li> <li>Offline on the robot (no or slow internet connection), currently in Progress         #89</li> <li>Online on a server-cluster, with         gRPC.</li> <li>Shifting computation loads away from the robot and into the cloud.</li> <li>Easily switch between Protocol Buffers   (PB) /   Flatbuffers (FB) as the messaging   format.</li> </ul>"},{"location":"home/#architecture","title":"Architecture","text":"<p>The following graphic provides a broad overview of SEEREPs components. The sensor data along with results from processing the data and annotations are stored in HDF5 files. SEEREP uses projects to group common information (e.g. a scanning campaign). The data can be saved locally on the robot or sent into the cloud with gRPC. Therefore, the computational load on the robot can be reduced and algorithms can fetch the data subset which they actually need.</p> <p></p> <p>A more detailed version, with all ROS packages and message types is available in the package overview.</p>"},{"location":"reference/api/","title":"gRPC API","text":""},{"location":"reference/api/#grpc-api","title":"gRPC API","text":"<p>This page provides a summary of the available gRPC services offered by SEEREP. It is recommended to use FlatBuffers for serialization, as the latest updates and features utilize it. Protocol Buffers might lack certain features and could potentially be discontinued in the future, as indicated by issue#372. The services are implemented in the seerep_server package.</p> <p>The streaming column in the following tables indicates whether the client or server can send <code>1 ... N</code> messages during the service call.</p>"},{"location":"reference/api/#flatbuffers","title":"Flatbuffers","text":""},{"location":"reference/api/#metaoperations","title":"MetaOperations","text":"Service Description Request Message Response Message Streaming CreateProject Create a new SEEREP project ProjectCreation ProjetInfo - GetProjects Get all current projects Empty ProjetInfos - LoadProjects Load all unindexed projects Empty ProjetInfos - DeleteProject Delete a project ProjectInfo Empty - GetOverallTimeInterval Get the total timespan of a data type UuidDatatypePair TimeInterval - GetOverallBoundingBox Get the full extent of a data type UuidDatatypePair Boundingbox - GetAllCategories Get all categories of a data type UuidDatatypePair StringVector - GetAllLabels Get all labels in a category of a data type UuidDatatypeWithCategory StringVector -"},{"location":"reference/api/#imageservice","title":"ImageService","text":"Service Description Request Message Response Message Streaming GetImage Get images based on a query Query Image Server TransferImage Transfer images to SEEREP Image ServerResponse Client AddLabels Add labels to existing images DatasetUuidLabel ServerResponse Client"},{"location":"reference/api/#cameraintrinsicsservice","title":"CameraIntrinsicsService","text":"Service Description Request Message Response Message Streaming GetCameraIntrinsics Get a specific camera instrinic CameraIntrinsicsQuery CameraIntrinsics - TransferCameraIntrinsics Transfer camera intrinsics to SEEREP CameraIntrinsics ServerResponse -"},{"location":"reference/api/#pointcloudservice","title":"PointCloudService","text":"Service Description Request Message Response Message Streaming GetPointCloud2 Get point clouds based on a query Query PointCloud2 Server TransferPointCloud2 Transfer point clouds to SEEREP PointCloud2 ServerResponse Client AddLabels Add labels to existing point clouds DatasetUuidLabel ServerResponse Client"},{"location":"reference/api/#tfservice","title":"TfService","text":"Service Description Request Message Response Message Streaming TransferTransformStamped Add a transformation to SEEREP TransformStamped ServerResponse Client GetFrames Get all frames of a project FrameQuery StringVector - GetTransformStamped Get a transformation from SEEREP TransformStampedQuery TransformStamped -"},{"location":"reference/api/#pointservice","title":"PointService","text":"Service Description Request Message Response Message Streaming GetPoint Get points based on a query Query PointStamped Server TransferPoint Transfer points to SEEREP PointStamped ServerResponse Client AddAttribute Add attribute to existing points AttributesStamped ServerResponse Client"},{"location":"reference/api/#protocol-buffers","title":"Protocol Buffers","text":""},{"location":"reference/api/#metaoperations_1","title":"MetaOperations","text":"Service Description Request Message Response Message Streaming CreateProject Create a new SEEREP project ProjectCreation ProjetInfo - GetProjects Get all current projects Empty ProjetInfos - GetOverallTimeInterval Get the total timespan of a data type UuidDatatypePair TimeInterval - GetOverallBoundingBox Get the full extent of a data type UuidDatatypePair Boundingbox - GetAllCategories Get all categories of a data type UuidDatatypePair StringVector - GetAllLabels Get all labels in a category of a data type UuidDatatypeWithCategory StringVector -"},{"location":"reference/api/#imageservice_1","title":"ImageService","text":"Service Description Request Message Response Message Streaming GetImage Get images based on a query Query Image Server TransferImage Transfer images to SEEREP Image ServerResponse -"},{"location":"reference/api/#cameraintrinsicsservice_1","title":"CameraIntrinsicsService","text":"Service Description Request Message Response Message Streaming GetCameraIntrinsics Get a specific camera instrinic CameraIntrinsicsQuery CameraIntrinsics - TransferCameraIntrinsics Transfer camera intrinsics to SEEREP CameraIntrinsics ServerResponse -"},{"location":"reference/api/#pointcloudservice_1","title":"PointCloudService","text":"Service Description Request Message Response Message Streaming GetPointCloud2 Get point clouds based on a query Query PointCloud2 Server TransferPointCloud2 Transfer point clouds to SEEREP PointCloud2 ServerResponse -"},{"location":"reference/api/#tfservice_1","title":"TfService","text":"Service Description Request Message Response Message Streaming TransferTransformStamped Add a transformation to SEEREP TransformStamped ServerResponse - GetFrames Get all frames of a project FrameQuery StringVector - GetTransformStamped Get a transformation from SEEREP TransformStampedQuery TransformStamped -"},{"location":"reference/packages/","title":"Package Overview","text":"<p>This page provides an overview of all the ROS-Packages used in SEEREP.</p>"},{"location":"reference/packages/#general-seerep-structure","title":"General SEEREP Structure","text":"<p>The general structure of SEEREP is schematically illustrated in the following graphic.</p> <p>SEEREP can be split into two parts, one of which runs on the robot (left box) and one which runs on a server clusters (right box). The communication is handled via gRPC and protocol-buffers (PB) or flatbuffers (FB).</p> <p></p>"},{"location":"reference/packages/#packages","title":"Packages","text":"<p>In the following, each package will be described in more detail.</p>"},{"location":"reference/packages/#seerep-hdf5","title":"seerep-hdf5","text":"<p>The\u00a0<code>seerep-hdf5</code>\u00a0unit provides access to the hdf5 files to store or retrieve data. The unit is split into three packages\u00a0<code>seerep-hdf5-core</code>,\u00a0<code>seerep-hdf5-pb</code>\u00a0and\u00a0<code>seerep-hdf5-fb</code>. This is to have a server-core which is independent of the message format, so that it's possible to easily switch between PB and FB or any other message format.</p> <ul> <li> <p>The main task for the <code>seerep-core</code> is to read UUIDs, bounding boxes (BB),   time/semantic information on provided indices from the hdf5-files. The only   write operation of the core is to create new hdf5-files. Due to the   independence of FB and PB, new communication-messages are added to seerep-msgs   (<code>seerep-msgs/core</code>).</p> </li> <li> <p><code>seerep-hdf5-pb</code> and <code>seerep-hdf5-fb</code> provide methods to read or write   point clouds, images and transformations from PB or FB  messages.</p> </li> </ul>"},{"location":"reference/packages/#seerep-srv","title":"seerep-srv","text":"<p>The <code>seerep-srv</code> is split into four parts <code>seerep-server</code>, <code>seerep-core</code> and <code>seerep-core-pb</code>, <code>seerep-core-fb</code>.</p> <ul> <li> <p>The <code>seerep-server</code> provides the top level interface for the SEEREP server   cluster, services which clients can be registered here. The server passes   request to the corresponding unit in the layer below (see graphic).</p> </li> <li> <p>The <code>seerep-core-pb</code> / <code>seerep-core-fb</code>  writes incoming PB / FB messages to   the hdf5 files. In case of a query the <code>seerep-core</code> is asked for the UUIDs of   the datasets which match the query parameters.</p> </li> </ul>"},{"location":"reference/packages/#seerep-msgs","title":"seerep-msgs","text":"<p>The <code>seerep-msgs</code> package defines all the PB, FB and core messages used in SEEREP.</p>"},{"location":"reference/packages/#seerep-ros","title":"seerep-ros","text":"<p><code>seerep-ros</code> provides three packages which run on the robot itself. The <code>seerep_ros_conversions_pb/fb</code> packages simply convert ROS messages to PB/FB and vice versa. The second package <code>seerep_ros_communication</code> is used to save sensor information like images and point clouds on the robot, or in case of a good internet connection to the remote server-cluster. Further, the robot is able to query the server for information to support his understanding of the environment and aid its navigation.</p> <ul> <li> <p>The <code>seerep_ros_communication\\client</code> is responsible for sending sensor   information directly to the remote server.</p> </li> <li> <p>The <code>seerep_ros_communication\\querier</code> is used to get information from the   remote server.</p> </li> <li> <p><code>seerep_ros_communication\\hdf5-dump</code> is used to save sensor information on a   hard drive which is located on the robot.</p> </li> </ul>"},{"location":"reference/packages/#seerep-com","title":"seerep-com","text":"<p><code>seerep-com</code> is used to define the gRPC services in PB and FB.</p>"},{"location":"reference/pytests-message-abstractions/","title":"Flatbuffers Message Abstractions","text":"<p>The message abstractions are a rather experimental way to more easily create test variations.</p> <p>Note: This API is subject to change in the future, as some functionality should get decoupled in a more elegant way.</p> <p>It is currently used to create variations for tests of <code>gRPC_fb_getInstances.py</code>. The tests can be found under test_gRPC_fb_getInstances.py.</p> <p>The idea is to provide default implementations for common datatypes, but still allow for modification of parts of that datatype. In some <code>flatbuffers</code> implementations there exists a API for mutability for that but unfortunately not for python and even when it would, it would still impose other problems.</p> <p>To tackle the problem, a wrapper is used where a set of enums, which corresponds to a datatype's components, can be given in order to assemble a datatype with those components \"activated\". Function pointers are used to define what should happen if a component is inactive (often just <code>None</code> is returned) and what should happen if a component is active.</p> <p>Datatype implementations for <code>Query</code> and <code>QueryInstance</code> and their abstraction model can be found here.</p>"},{"location":"reference/pytests-message-abstractions/#defining-new-datatypes-for-variation-testing","title":"Defining new datatypes for variation testing","text":"<p>First the datatype has to be defined as a class inheriting from FrozenEnum provided through datastructures.py, which is essentially a unmodifiable enum.</p> <p>This is done for the <code>FbQuery</code> datatype, which corresponding <code>flatbuffers</code> definition can be found here.</p> <pre><code>class EnumFbQuery(FrozenEnum):\n    POLYGON = auto()  # def: None\n    FULLY_ENCAPSULATED = auto()  # def: False\n    IN_MAP_FRAME = auto()  # def: True\n    TIMEINTERVAL = auto()  # def: None\n    LABEL = auto()  # def: None\n    SPARQL_QUERY = auto()  # def: None\n    ONTOLOGY_URI = auto()  # def: None\n    MUST_HAVE_ALL_LABELS = auto()  # def: False\n    PROJECTUUID = auto()  # def: None\n    INSTANCEUUID = auto()  # def: None\n    DATAUUID = auto()  # def: None\n    WITHOUTDATA = auto()  # def: False\n    MAX_NUM_DATA = auto()  # def: None\n    SORT_BY_TIME = auto()  # def: False\n</code></pre> <p>Then <code>FbQuery</code> inherits from <code>MsgsFb</code>, which itself is a template type defined in msgs_base.py.</p> <pre><code>class FbQuery(MsgsFb[Query.Query]):\n    def _set_enum_func_mapping(self) -&gt; Dict[EnumFbQuery, MsgsFunctions]:\n        return {\n            EnumFbQuery.POLYGON: MsgsFunctions(\n                lambda: None, lambda: Dtypes.Fb.polygon2D(self.builder)\n            ),\n            EnumFbQuery.FULLY_ENCAPSULATED: MsgsFunctions(\n                lambda: False, lambda: True\n            ),\n            EnumFbQuery.IN_MAP_FRAME: MsgsFunctions(\n                lambda: True, lambda: False\n            ),\n            EnumFbQuery.TIMEINTERVAL: MsgsFunctions(\n                lambda: None, lambda: Dtypes.Fb.time_interval(self.builder)\n            ),\n            EnumFbQuery.LABEL: MsgsFunctions(\n                lambda: None, lambda: Dtypes.Fb.label_category(self.builder)\n            ),\n            EnumFbQuery.SPARQL_QUERY: MsgsFunctions(\n                lambda: None, lambda: Dtypes.Fb.sparql_query(self.builder)\n            ),\n            EnumFbQuery.ONTOLOGY_URI: MsgsFunctions(\n                lambda: None, lambda: Dtypes.Fb.ontology_uri(self.builder)\n            ),\n            EnumFbQuery.MUST_HAVE_ALL_LABELS: MsgsFunctions(\n                lambda: False, lambda: True\n            ),\n            EnumFbQuery.PROJECTUUID: MsgsFunctions(\n                lambda: None,\n                lambda: Dtypes.Fb.projectuuid(self.builder, self.channel),\n            ),\n            EnumFbQuery.INSTANCEUUID: MsgsFunctions(\n                lambda: None, lambda: self.instanceuuid()\n            ),\n            EnumFbQuery.DATAUUID: MsgsFunctions(\n                lambda: None,\n                lambda: Dtypes.Fb.datauuid(self.builder, self.channel),\n            ),\n            EnumFbQuery.WITHOUTDATA: MsgsFunctions(lambda: False, lambda: True),\n            EnumFbQuery.MAX_NUM_DATA: MsgsFunctions(\n                lambda: None, lambda: Dtypes.Fb.max_num_data()\n            ),\n            EnumFbQuery.SORT_BY_TIME: MsgsFunctions(\n                lambda: False, lambda: True\n            ),\n        }\n\n    @expect_component(EnumFbQuery.PROJECTUUID)\n    def instanceuuid(self) -&gt; List[int]:\n        return Dtypes.Fb.intanceuuid(\n            self.builder,\n            self.channel,\n            self.get_component(EnumFbQuery.PROJECTUUID),\n        )\n\n    @expect_component(EnumFbQuery.PROJECTUUID)\n    def datauuid(self) -&gt; List[int]:\n        return Dtypes.Fb.datauuid(\n            self.builder, self.channel, self.get_component(EnumFbQuery.DATAUUID)\n        )\n\n    def _assemble_datatype_instance(self):\n        polygon = self.get_component(EnumFbQuery.POLYGON)\n        fully_encapsulated = self.get_component(EnumFbQuery.FULLY_ENCAPSULATED)\n        in_map_frame = self.get_component(EnumFbQuery.IN_MAP_FRAME)\n        timeinterval = self.get_component(EnumFbQuery.TIMEINTERVAL)\n        label = self.get_component(EnumFbQuery.LABEL)\n        must_have_all_labels = self.get_component(\n            EnumFbQuery.MUST_HAVE_ALL_LABELS\n        )\n        projectuuid = self.get_component(EnumFbQuery.PROJECTUUID)\n        instanceuuid = self.get_component(EnumFbQuery.INSTANCEUUID)\n        datauuid = self.get_component(EnumFbQuery.DATAUUID)\n        withoutdata = self.get_component(EnumFbQuery.WITHOUTDATA)\n        sort_by_time = self.get_component(EnumFbQuery.SORT_BY_TIME)\n\n        return fbh.createQuery(\n            self.builder,\n            timeinterval,\n            label,\n            must_have_all_labels,\n            projectuuid,\n            instanceuuid,\n            datauuid,\n            withoutdata,\n            polygon,\n            fully_encapsulated,\n            in_map_frame,\n            sort_by_time,\n        )\n</code></pre> <p>In <code>MsgsFb</code> <code>_set_enum_func_mapping()</code> is a abstractmethod which return type is a dictionary, which maps the enum types to <code>MsgsFunctions</code>. <code>MsgsFunction</code> itself is just a structure to wrap two function pointers. The first function pointer should be a pointer to the <code>default_function</code>, which gets called, if the component is not set to be active. The second function pointer is the one that gets called when the component is set active.</p> <p>On runtime it is checked if all elements of the enum are mapped. The functions are mostly mapped to default implementations for that specific component datatype. The default functions implementations can be inspected here at the bottom.</p> <p>The <code>@expect_component</code> decorator can be used to define dependencies between the component datatypes, e.g. for the <code>instanceuuid()</code> function to work, the <code>EnumFbQuery.PROJECTUUID</code> component must be set to active.</p> <p>Lastly the abstractmethod <code>_assemble_datatype_instance()</code> has to be implemented, in the function all of the wrapper managed components should be retrieved and the datatype should be built and returned. The base class makes sure that all the components at this point are set.</p>"},{"location":"reference/pytests-message-abstractions/#using-message-abstractions-for-testing","title":"Using message abstractions for testing","text":"<pre><code>def test_gRPC_getInstanceTypes(grpc_channel, project_setup):\n    _, proj_uuid = project_setup\n\n    ### check for instances on images\n    images_uuids, _, _ = send_imgs.send_labeled_images(proj_uuid, grpc_channel)\n    pcl_lst: List[PointCloud2.PointCloud2] = send_pcl.send_pointcloud(\n        proj_uuid, grpc_channel\n    )\n    img_uuid2point_map: Dict[str, PointStamped.PointStamped] = (\n        send_points.send_points(proj_uuid, grpc_channel)\n    )\n\n    # extract images ignore image uuids\n    images = [img[1] for img in images_uuids]\n\n    # retrieve the labelinstances of the bounding boxes\n    label_instances = []\n    for image in images:\n        for label_cat in image.labels:\n            for instance in label_cat.labels:\n                label_instances.append(instance.instanceUuid)\n\n    serv_man = ServiceManager(grpc_channel)\n\n    queryinst_builder = FbQueryInstance(\n        grpc_channel, enum_types={EnumFbQueryInstance.DATATYPE}\n    )\n    queryinst_builder.set_active_function(\n        EnumFbQueryInstance.DATATYPE, lambda: Datatype.Datatype.Image\n    )\n    queryinst_builder.assemble_datatype_instance()\n\n    instance_uuidspp = serv_man.call_get_instances_fb(\n        queryinst_builder.builder, queryinst_builder.datatype_instance\n    )\n\n    label_instances = sorted(label_instances)\n\n    instance_uuids = get_sorted_uuids_per_proj(instance_uuidspp)\n\n    assert instance_uuids == label_instances\n</code></pre> <p>In this function all the possible datatypes with attached instances are tested (this is just a snippet of that particular function).</p> <p>The message abstractions are used by creating a object of <code>FbQueryInstance</code> first and setting the only active enum to <code>EnumFbQueryInstance.DATATYPE</code> using the <code>enum_types</code> variable on initialization, as this is the only relevant component to be modified for the test. In this case it would be relatively easy to test different sets of components together e.g. testing for interference when specific datatypes are set and while a polygon is used to restrict the relevant area.</p> <p>After that <code>set_active_function()</code> is used to set a different function pointer to the active component's function pointer. This essentially sets the second component of a <code>MsgsFunction</code> type in the dictionary returned by <code>_set_enum_func_mapping()</code>, which is discussed in the previous section.</p> <p>Lastly if a change to the dictionary has been done using <code>set_active_function()</code> or <code>set_mapped_functions()</code>, the <code>assemble_datatype_instance()</code> has to be called to reassemble the underlying datatype.</p> <p>Note: On creation of the instance the datatype is assembled automatically in it's constructor.</p> <p>Now the assembled datatype can be accessed using the property <code>queryinst_builder.datatype_instance</code> and the underlying flatbuffers builder can be accessed by using <code>queryinst_builder.builder</code> for further use, e.g. like in this case calling the service function <code>call_get_instances_fb()</code> using the ServiceManager.</p> <p>Note: The <code>MsgsBase</code> class provides it's own <code>ServiceManager</code> property for building components, but that one shouldn't be used as it could change in the future.</p> <p>Another snippet to highlight is the following where one of the components of the datatype itself is inheriting from <code>MsgsFb</code>.</p> <pre><code>def test_gRPC_getInstanceQueryTimeinterval(grpc_channel, project_setup):\n    _, proj_uuid = project_setup\n\n    serv_man = ServiceManager(grpc_channel)\n\n    # only send pictures to ease the testing process\n    images_uuids, _, _ = send_imgs.send_labeled_images(proj_uuid, grpc_channel)\n\n    # extract images ignore image uuids\n    images = [img[1] for img in images_uuids]\n\n    ### time interval tests\n    time_offset = 1000\n    cur_time = int(time.time())\n\n    min_time_ = cur_time - time_offset\n    max_time_ = cur_time + time_offset\n\n    query_builder = FbQuery(grpc_channel, enum_types={EnumFbQuery.TIMEINTERVAL})\n    queryinst_builder = FbQueryInstance(\n        grpc_channel, enum_types={EnumFbQueryInstance.QUERY}\n    )\n\n    # test for time interval\n    min_timestamp = fbh.createTimeStamp(queryinst_builder.builder, min_time_, 0)\n    max_timestamp = fbh.createTimeStamp(queryinst_builder.builder, max_time_, 0)\n\n    img_time_interval = fbh.createTimeInterval(\n        queryinst_builder.builder, min_timestamp, max_timestamp\n    )\n\n    query_builder.set_active_function(\n        EnumFbQuery.TIMEINTERVAL, lambda: img_time_interval\n    )\n\n    queryinst_builder.set_active_function(\n        EnumFbQueryInstance.QUERY, lambda: query_builder.datatype_instance\n    )\n\n    query_builder.assemble_datatype_instance()\n\n    queryinst_builder.assemble_datatype_instance()\n\n    instance_uuids_intimeinterval = get_sorted_uuids_per_proj(\n        serv_man.call_get_instances_fb(\n            queryinst_builder.builder, queryinst_builder.datatype_instance\n        )\n    )\n\n    min_time_ = cur_time - 2 * time_offset\n    max_time_ = cur_time - time_offset\n\n    min_timestamp = fbh.createTimeStamp(queryinst_builder.builder, min_time_, 0)\n    max_timestamp = fbh.createTimeStamp(queryinst_builder.builder, max_time_, 0)\n\n    img_time_interval = fbh.createTimeInterval(\n        queryinst_builder.builder, min_timestamp, max_timestamp\n    )\n\n    query_builder.set_active_function(\n        EnumFbQuery.TIMEINTERVAL, lambda: img_time_interval\n    )\n\n    query_builder.assemble_datatype_instance()\n\n    queryinst_builder.assemble_datatype_instance()\n\n    instance_uuids_outtimeinterval = get_sorted_uuids_per_proj(\n        serv_man.call_get_instances_fb(\n            queryinst_builder.builder, queryinst_builder.datatype_instance\n        )\n    )\n\n    label_instances = get_instances_from_imgs(images)\n\n    assert len(instance_uuids_outtimeinterval) == 0\n    assert sorted(label_instances) == sorted(instance_uuids_intimeinterval)\n</code></pre> <p>Here <code>query_builder</code> is used to build the <code>Query.Query</code> datatype in order to supply that one to the <code>queryinst_builder</code> query component. It is important that <code>query_builder.assemble_datatype_instance()</code> is called before <code>queryinst_builder.assemble_datatype_instance()</code>, otherwise the changes by setting the active function on <code>query_builder</code> are not reflected in the <code>queryinst_builder.datatype_instance</code>.</p>"},{"location":"reference/pytests-message-abstractions/#inner-workings-of-the-msgsfb-and-msgsbase-classes","title":"Inner workings of the <code>MsgsFb</code> and <code>MsgsBase</code> classes","text":"<p>Meaning of Symbols and Notations in this diagram:</p> <ul> <li>Rectangular boxes: instance methods</li> <li>Ellipsis: instance variables</li> <li>Line arrows (with text): calls to methods or setting variables (with the help   of those variables specified by the text)</li> <li>Line arrows with numbers: show the order in which things are done</li> <li>dotted arrows outgoing: Getter methods/properties</li> <li>dotted arrows incoming: Setter methods/properties</li> <li>red colored text: already used functionality in the examples above</li> <li>purple colored text: <code>@abstractmethod</code> also used above</li> <li>blue colored text: has a special meaning, is not mirrored exactly by the   implementation</li> </ul> <p>Note: Some details are not shown like the validation methods for the given enum type. But they are not neccessary to understand the structure.</p> <p>First in the initialization phase variables (<code>_builder</code>, <code>_service_manager</code>, <code>_channel</code>, <code>_active_enums</code>) are set and managed by the <code>MsgsFb</code> instance, those are needed for the assembly of the datatype instance later. <code>_builder</code> is a simply a flatbuffers builder. <code>channel</code> is used to create <code>ServiceManager</code> instance and manage a <code>grpc_channel</code> type variable. At last <code>_active_enums</code> is a set of enum elements, which will be used to specify which component of the datatype is \"active\" (i.e. which component is set by the <code>active_function</code> of the <code>MsgsFunctions</code> class).</p> <p>After that the <code>_enum_func_mapping</code> variable is set by the <code>_set_enum_func_mapping()</code> function. This variable can also get manipulated by <code>set_active_function()</code> or <code>set_mapped_functions()</code>. Then <code>_assemble_components()</code> is called, which makes sure that the <code>_components</code> are set, i.e. the functions in the <code>_enum_func_mapping</code> are called and the components are set by those <code>default_functions</code> or those <code>active_functions</code>, if their corresponding enum is in the <code>_active_enums</code> set.</p> <p>Note: <code>_components</code> are implemented as multiple dynamically at runtime created instance variables with the name of the component specified by the enum element name.</p> <p>Finally the on the instance callable <code>assemble_datatype_instance()</code> method triggers a rebuild of the <code>_assembled_datatype_instance</code>, by first refreshing the components and then calling the <code>_assemble_datatype_instance()</code> method. The <code>assemble_datatype_instance()</code> method gets also called in the <code>__init__()</code> method, such that the message abstractions always try to guarantee a set <code>datatype_instance</code> variable.</p>"},{"location":"reference/python-helpers/","title":"Available Modules","text":""},{"location":"reference/python-helpers/#commonpy","title":"common.py","text":"<p>Contains common functions like <code>get_grpc_channel()</code> and some functions for passing into <code>boltons.iterutils.remap</code>.</p> <p>The source is located here.</p>"},{"location":"reference/python-helpers/#fb_helperpy","title":"fb_helper.py","text":"<p>This is a module provided through the seerep_grpc package. It provides functions to construct a subset of the SEEREP flatbuffers message in one function call. Most of the functions only return the component for further composition into another datatype. If the component itself should be serialized <code>builder.Finish()</code> as well as <code>builder.Output()</code> need to be called, on the from the function retrieved value.</p> <p>The source is located here.</p>"},{"location":"reference/python-helpers/#service_managerpy","title":"service_manager.py","text":"<p>Contains a class <code>ServiceManager</code> which when instantiated can be used to instantly call the services with the return values of the <code>fb_helper.py</code> functions, i.e. the <code>builder.Finish()</code> and <code>builder.Output()</code> calls are done in the <code>ServiceManager</code> methods. Example usage can be found in msg_abs/msgs.py , e.g.:</p> <pre><code>        @classmethod\n        def datauuid(cls, builder: Builder, channel: Channel) -&gt; List[int]:\n            query_fb = FbQuery(channel).datatype_instance\n            serv_man = ServiceManager(channel)\n            images = serv_man.call_get_images_fb(builder, query_fb)\n            points = serv_man.call_get_points_fb(builder, query_fb)\n            pcl2s = serv_man.call_get_pointcloud2_fb(builder, query_fb)\n\n            image_uuids = sorted(\n                [image.Header().UuidMsgs().decode() for image in images]\n            )\n            point_uuids = sorted(\n                [point.Header().UuidMsgs().decode() for point in points]\n            )\n            pcl2_uuids = sorted(\n                [pcl.Header().UuidMsgs().decode() for pcl in pcl2s]\n            )\n\n            # debugging\n            # print(\"images: \" + str(image_uuids))\n            # print(\"points: \" + str(point_uuids))\n            # print(\"pcls: \" + str(pcl2_uuids))\n\n            # fill up return list with every second uuid\n            ret_lst = [\n                builder.CreateString(image_uuids[i])\n                for i in range(0, len(image_uuids), 2)\n            ]\n            ret_lst += [\n                builder.CreateString(point_uuids[i])\n                for i in range(0, len(point_uuids), 2)\n            ]\n            ret_lst += [\n                builder.CreateString(pcl2_uuids[i])\n                for i in range(0, len(pcl2_uuids), 2)\n            ]\n</code></pre> <p>The source is located here.</p> <p>Note: This module is currently incomplete and contains only a subset of the available service calls.</p>"},{"location":"reference/python-helpers/#fb_to_dictpy","title":"fb_to_dict.py","text":""},{"location":"reference/python-helpers/#fb_flatc_dict","title":"fb_flatc_dict()","text":"<p>The <code>fb_flatc_dict</code> function can be used to convert serialized <code>flatbuffers</code> objects to a python dictionary. More information can be found by looking at the docstring:</p> <pre><code>    Converts a binary flatbuffers object to a python dictionary using it's IDL\n    file.\n\n    This function should only be used for debugging or testing purposes, as it\n    alleviates the advantage of flatbuffers lessening the amount of copied data.\n\n    This implementation uses temporary files in /tmp for conversion.\n\n    Args:\n        fb_obj: The bytearray object as returned by builder.Output().\n        schema_file_name: The to `fb_obj` corresponding datatype in the\n        `SchemaFileNames` format\n\n    Returns:\n        A python dictionary containing the objects attribute information.\n</code></pre>"},{"location":"reference/python-helpers/#catkin_find_schema_dir","title":"catkin_find_schema_dir()","text":"<p>Looking at the docstring should reveal everything to know about this function:</p> <pre><code>    Tries to find the schema directory on the system using `catkin locate`.\n\n    Args:\n        ros_pkg_name: The name of the ros package containing the relevant\n        schema files\n        sub_dir: The name of the subdir of the package dir containing the\n        relevant schema files\n\n    Returns:\n        The schema directory on the system if found.\n\n    Raises:\n        FileNotFoundError: If the path on the system is not present.\n        ChildProcessError: If `catkin locate` returns something on stderr\n        or failed otherwise\n</code></pre>"},{"location":"reference/python-helpers/#schemafilenames","title":"SchemaFileNames","text":"<p>A enum type class, to map the available flatbuffers type schema file names. Only used as a type specifier for <code>fb_flatc_dict</code>.</p>"},{"location":"tutorials/images/","title":"Sending &amp; querying images","text":""},{"location":"tutorials/images/#sending-images","title":"Sending images","text":"<p>In this example we will send images with labels to SEEREP.</p> <p>In order to save images, we need to mandatorily provide the intrinsics of the camera used to capture them. After the successfully saving the camera intrinsics, we need to provide the uuid of it along with the images. SEEREP will ensure that the Camera Intrinsics UUID provided with an image has a UUID stored against it.</p> <p>Additionally we add some coordinate transformations at the end.</p> <p>Source: examples/python/gRPC/images/gRPC_pb_sendLabeledImage.py</p> <pre><code>#!/usr/bin/env python3\n# NOTE: This file is referenced in the following mkdocs files:\n#   images.md\n# Any changes done in here will be reflected in there\nimport time\nimport uuid\nfrom typing import List, Optional, Tuple\n\nimport numpy as np\nfrom google.protobuf import empty_pb2\nfrom grpc import Channel\nfrom seerep.pb import camera_intrinsics_pb2 as cameraintrinsics\nfrom seerep.pb import (\n    camera_intrinsics_service_pb2_grpc as camintrinsics_service,\n)\nfrom seerep.pb import image_pb2 as image\nfrom seerep.pb import image_service_pb2_grpc as imageService\nfrom seerep.pb import label_category_pb2, label_pb2\nfrom seerep.pb import meta_operations_pb2_grpc as metaOperations\nfrom seerep.pb import projectCreation_pb2 as projectCreation\nfrom seerep.pb import tf_service_pb2_grpc as tfService\nfrom seerep.pb import transform_stamped_pb2 as tf\nfrom seerep.util.common import get_gRPC_channel\n\n\ndef send_labeled_images(\n    target_proj_uuid: Optional[str] = None,\n    grpc_channel: Channel = get_gRPC_channel(),\n) -&gt; Tuple[\n    List[List[image.Image]], List[int], cameraintrinsics.CameraIntrinsics\n]:\n    \"\"\"sends test images via the given grpc_channel to the specified target\n    project uuid\"\"\"\n\n    # 1. Get gRPC service objects\n    stub = imageService.ImageServiceStub(grpc_channel)\n    stubTf = tfService.TfServiceStub(grpc_channel)\n    stubMeta = metaOperations.MetaOperationsStub(grpc_channel)\n    stubCI = camintrinsics_service.CameraIntrinsicsServiceStub(grpc_channel)\n\n    # 2. Check if we have an existing test project (or target_proj_uuid is set),\n    # if not, one is created.\n    if target_proj_uuid is None:\n        # 3. Get all projects from the server\n        response = stubMeta.GetProjects(empty_pb2.Empty())\n        for project in response.projects:\n            print(project.name + \" \" + project.uuid)\n            if project.name == \"testproject\":\n                target_proj_uuid = project.uuid\n\n        if target_proj_uuid is None:\n            # 4. create a project\n            creation = projectCreation.ProjectCreation(\n                name=\"testproject\", mapFrameId=\"map\"\n            )\n            projectCreated = stubMeta.CreateProject(creation)\n            target_proj_uuid = projectCreated.uuid\n\n    theTime = int(time.time())\n\n    #####\n    # A valid camera intrinsics UUID is needed here for succesful storage\n    # of Images\n    # Add new Camera Intrinsics with placeholder data\n\n    ciuuid = str(uuid.uuid4())\n\n    camin = cameraintrinsics.CameraIntrinsics()\n\n    camin.header.stamp.seconds = 4\n    camin.header.stamp.nanos = 3\n\n    camin.header.frame_id = \"camintrinsics\"\n\n    camin.header.uuid_project = target_proj_uuid\n    camin.header.uuid_msgs = ciuuid\n\n    camin.region_of_interest.x_offset = 2\n    camin.region_of_interest.y_offset = 1\n    camin.region_of_interest.height = 5\n    camin.region_of_interest.width = 4\n    camin.region_of_interest.do_rectify = 4\n\n    camin.height = 5\n    camin.width = 4\n\n    camin.distortion_model = \"plumb_bob\"\n\n    camin.distortion.extend(list(range(0, 3)))\n\n    camin.intrinsic_matrix.extend([3, 4, 5, 10, 7, 8, 9, 10, 11])\n    camin.rectification_matrix.extend([3, 4, 5, 6, 7, 8, 9, 10, 11])\n    camin.projection_matrix.extend([3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14])\n\n    camin.binning_x = 6\n    camin.binning_y = 7\n\n    camin.maximum_viewing_distance = 5\n\n    stubCI.TransferCameraIntrinsics(camin)\n\n    # 5. Create ten images\n    # for debugging and testing this example add all sent images to a list\n    sent_images_list: List[Tuple[str, image.Image]] = []\n\n    for n in range(10):\n        theImage = image.Image()\n\n        rgb = []\n        lim = 256  # 256 x 256 pixels\n        for i in range(lim):\n            for j in range(lim):\n                x = float(i) / lim\n                y = float(j) / lim\n                z = float(j) / lim\n                r = np.ubyte((x * 255.0 + n) % 255)\n                g = np.ubyte((y * 255.0 + n) % 255)\n                b = np.ubyte((z * 255.0 + n) % 255)\n                rgb.append(r)\n                rgb.append(g)\n                rgb.append(b)\n\n        # Add image meta-data\n        theImage.header.frame_id = \"camera\"\n        theImage.header.stamp.seconds = theTime + n\n        theImage.header.stamp.nanos = 0\n        theImage.header.uuid_project = target_proj_uuid\n        theImage.height = lim\n        theImage.width = lim\n        theImage.encoding = \"rgb8\"\n        theImage.step = 3 * lim\n        theImage.uuid_camera_intrinsics = ciuuid\n\n        # Add image data\n        theImage.data = bytes(rgb)\n\n        # 5. create label\n        labelStr = [\"label1\", \"label2\"]\n        for iCategory in [\"category A\", \"category B\"]:\n            labelsCategory = label_category_pb2.LabelCategory()\n            labelsCategory.category = iCategory\n            labelsCategory.datumaroJson = \"a very valid datumaro json\"\n\n            for labelAct in labelStr:\n                label = label_pb2.Label()\n                label.label = labelAct\n                label.labelIdDatumaro = 1\n                label.instanceUuid = str(uuid.uuid4())\n                label.instanceIdDatumaro = 22\n                labelsCategory.labels.append(label)\n\n            theImage.labels.append(labelsCategory)\n\n        # 8. Send image to the server\n        uuidImg = stub.TransferImage(theImage)\n\n        # also add them to the list\n        sent_images_list.append((uuidImg.message, theImage))\n\n    # a list for debugging and testing, if interpolated coordinates\n    # according to timestamp of the images and tfs are correct\n    tf_times: List[int] = []\n\n    # 8. Add coordinate transformations and send them to the server\n    theTf = tf.TransformStamped()\n    theTf.header.frame_id = \"map\"\n    theTf.header.stamp.seconds = theTime\n    theTf.header.uuid_project = target_proj_uuid\n    theTf.child_frame_id = \"camera\"\n    theTf.transform.translation.x = 1\n    theTf.transform.translation.y = 2\n    theTf.transform.translation.z = 3\n    theTf.transform.rotation.x = 0\n    theTf.transform.rotation.y = 0\n    theTf.transform.rotation.z = 0\n    theTf.transform.rotation.w = 1\n    stubTf.TransferTransformStamped(theTf)\n    tf_times.append(theTf.header.stamp.seconds)\n\n    theTf.header.stamp.seconds = theTime + 10\n    theTf.transform.translation.x = 100\n    theTf.transform.translation.y = 200\n    theTf.transform.translation.z = 300\n    stubTf.TransferTransformStamped(theTf)\n    tf_times.append(theTf.header.stamp.seconds)\n\n    # return sent data\n    return sent_images_list, tf_times, camin\n\n\nif __name__ == \"__main__\":\n    sent_image_ls_data, _, _ = send_labeled_images()\n    camera_intrinsics_allimgs = {\n        intrins_uuid[1].uuid_camera_intrinsics\n        for intrins_uuid in sent_image_ls_data\n    }\n\n    # print statement to seperate the messages of the function\n    print()\n    print(\n        f\"camera intrinsics will be saved against the uuid(s): \"\n        f\"{camera_intrinsics_allimgs}\"\n    )\n    img_uuids = [img[0] for img in sent_image_ls_data]\n    for i, img_uuid in enumerate(img_uuids):\n        print(f\"the uuid of the sent image number {i} is: {img_uuid}\")\n</code></pre> <p>Output:</p> <pre><code>testproject 842de425-2d50-4adf-8aa3-6df257a7c76c\ntestproject ff739be8-cf0c-4657-bff0-f66f3e7f578d\n\ncamera intrinsics will be saved against the uuid(s): {'909c8439-36b6-44ff-9561-f7921de5d8e8'}\nthe uuid of the sent image number 0 is: 261a7b2c-297b-42db-93da-770e5f7f53cf\nthe uuid of the sent image number 1 is: feddb62d-fdfa-494a-8e4a-e1b2209134a6\nthe uuid of the sent image number 2 is: 6956ea01-b834-461f-85cf-5621e04f02fb\nthe uuid of the sent image number 3 is: 111e62dd-9aba-4fde-ae3d-ed3e3b6041f8\nthe uuid of the sent image number 4 is: 67138174-08a9-4943-848a-736bddd755b9\nthe uuid of the sent image number 5 is: 5e139007-9eea-4e71-9c5a-44f08c93027e\nthe uuid of the sent image number 6 is: c10eff49-4412-425d-99ef-d8b3f95c3806\nthe uuid of the sent image number 7 is: 708be3d8-7ddb-4ef5-9b00-37021b7b83ff\nthe uuid of the sent image number 8 is: 4ce47c5c-60d2-4f78-810f-ac730136f462\nthe uuid of the sent image number 9 is: 6c9ca46b-84fb-40d2-8523-2ad07284a43c\n</code></pre>"},{"location":"tutorials/images/#query-images","title":"Query images","text":"<p>Now we will query the previously send images with some criteria. Possible query parameters are:</p>"},{"location":"tutorials/images/#2d-polygon-spatial-query","title":"2D Polygon (spatial query)","text":"<p>Spatial queries in SEEREP are performed using a 2D polygon. This polygon should be simple (no more than 2 vertices on the same edge) and convex (no edges curving inward). This 2D polygon lies on a interval on the z-axis defined through a z-coordinate point and a height value. Queries are performed by forming an encompassing axis aligned bounding box from the polygon. This can lead to an AABB larger than the polygon and poses the potential problem of returning results to the user which are not fully inside the query polygon. That problem is resolved by providing a boolean variable called fullyEncapsulated`. If false, resultant polygons, which are partially inside the query polygon are also returned.</p>"},{"location":"tutorials/images/#a-time-interval-temporal-query","title":"A time interval (temporal query)","text":"<p>Temporal queries in SEEREP are performed using a time interval. When using image queries the stamp in the <code>header</code> of those images is used and when that time lies in the interval the image is returned as part of the response. The interval is closed.</p>"},{"location":"tutorials/images/#labels-semantic-query","title":"Labels (semantic query)","text":""},{"location":"tutorials/images/#projectuuids","title":"ProjectUuids","text":"<p>Only performs the query in these included projects specified by their uuids.</p>"},{"location":"tutorials/images/#withoutdata","title":"WithoutData","text":"<p>If the pixel data of the image should not be returned in order to save bandwith.</p>"},{"location":"tutorials/images/#inmapframe","title":"InMapFrame","text":"<p>Whether the query is done in the map frame. If not, the provided polygon for the spatial query will be transformed from the geodesic coordinates of the project into the map frame beforehand.</p>"},{"location":"tutorials/images/#example-code-for-querying-images","title":"Example code for querying images","text":"FlatbuffersProtocol Buffers <p>Source: examples/python/gRPC/images/gRPC_fb_queryImage.py</p> <pre><code>#!/usr/bin/env python3\n# NOTE: This file is referenced in the following mkdocs files:\n#   images.md\n# Any changes done in here will be reflected in there\nimport sys\nfrom typing import List\n\nimport flatbuffers\nfrom grpc import Channel\nfrom seerep.fb import Image\nfrom seerep.fb import image_service_grpc_fb as imageService\nfrom seerep.util.common import get_gRPC_channel\nfrom seerep.util.fb_helper import (\n    create_label,\n    create_label_category,\n    createPoint2d,\n    createPolygon2D,\n    createQuery,\n    createTimeInterval,\n    createTimeStamp,\n    getOrCreateProject,\n)\n\n\ndef query_images_raw(\n    fbb: flatbuffers.Builder,\n    grpc_channel: Channel,\n    target_proj_uuid: str,\n    *args,\n    **kwargs,\n) -&gt; List[bytearray]:\n    \"\"\"\n    Query images from SEEREP and return the raw FlatBuffer buffers.\n\n    Args:\n        grpc_channel (Channel): gRPC channel to communicate with the server.\n        target_proj_uuid (str): UUID of the target project.\n        *args: Variable args to pass to the query.\n        **kwargs: Keyword args to pass to the query.\n\n    Returns:\n        List[bytearray]: A list buffers of images matching the query.\n    \"\"\"\n    image_service_stub = imageService.ImageServiceStub(grpc_channel)\n\n    project_uuid_buffer = fbb.CreateString(target_proj_uuid)\n\n    query = createQuery(\n        fbb, *args, projectUuids=[project_uuid_buffer], **kwargs\n    )\n\n    fbb.Finish(query)\n    query_buf = fbb.Output()\n\n    return image_service_stub.GetImage(bytes(query_buf))\n\n\ndef query_images(\n    fbb: flatbuffers.Builder,\n    grpc_channel: Channel,\n    target_proj_uuid: str,\n    *args,\n    **kwargs,\n) -&gt; List[Image.Image]:\n    \"\"\"\n    Query images from SEEREP.\n\n    Args:\n        grpc_channel (Channel): gRPC channel to communicate with the server.\n        target_proj_uuid (str): The UUID of the target project.\n        *args: Variable args to pass to the query.\n        **kwargs: Keyword args to pass to the query.\n\n    Returns:\n        List[Image.Image]: A list of images matching the query.\n    \"\"\"\n    return [\n        Image.Image.GetRootAs(img)\n        for img in query_images_raw(\n            fbb, grpc_channel, target_proj_uuid, *args, **kwargs\n        )\n    ]\n\n\nif __name__ == \"__main__\":\n    fbb = flatbuffers.Builder()\n    grpc_channel = get_gRPC_channel()\n    project_uuid = getOrCreateProject(fbb, grpc_channel, \"testproject\")\n\n    # create the data for the query\n    scale = 100\n    vertices = [\n        createPoint2d(fbb, x * scale, y * scale)\n        for x, y in [(-1.0, -1.0), (-1.0, 1.0), (1.0, 1.0), (1.0, -1.0)]\n    ]\n\n    polygon_2d = createPolygon2D(fbb, 700, -100, vertices)\n\n    time_min = createTimeStamp(fbb, 1610549273, 0)\n    time_max = createTimeStamp(fbb, 1938549273, 0)\n    time_interval = createTimeInterval(fbb, time_min, time_max)\n\n    project_uuids = [fbb.CreateString(project_uuid)]\n\n    labels = [\n        create_label(builder=fbb, label=label_str, label_id=i)\n        for i, label_str in enumerate([\"label1\", \"label2\"])\n    ]\n\n    labelsCategory = [\n        create_label_category(\n            builder=fbb,\n            labels=labels,\n            datumaro_json=\"a very valid datumaro json\",\n            category=\"category A\",\n        )\n    ]\n\n    matching_images = query_images(\n        fbb,\n        grpc_channel,\n        project_uuid,\n        polygon2d=polygon_2d,\n        labels=labelsCategory,\n        withoutData=True,\n        fullyEncapsulated=False,\n        inMapFrame=True,\n    )\n\n    if matching_images is None or len(matching_images) == 0:\n        print(\"No images matched the query.\")\n        sys.exit()\n\n    print(f\"Number of images matching the query: {len(matching_images)}\")\n\n    for img in matching_images:\n        print(\n            \"------------------------------------------------------------------\"\n        )\n        print(f\"Msg UUID: {img.Header().UuidMsgs().decode('utf-8')}\")\n        print(f\"Number of labels: {img.LabelsLength()}\")\n        if img.LabelsLength() &gt; 0:\n            print(\n                \"First label: \"\n                + img.Labels(0).Labels(0).Label().decode(\"utf-8\")\n            )\n    print(\"------------------------------------------------------------------\")\n</code></pre> <p>After sending the images, executing the query script results in the following output:</p> <pre><code>count of images: 10\n------------------------------------------------------------------\nuuidmsg: 111e62dd-9aba-4fde-ae3d-ed3e3b6041f8\ncount of labels: 2\nfirst label: label1\n------------------------------------------------------------------\nuuidmsg: 261a7b2c-297b-42db-93da-770e5f7f53cf\ncount of labels: 2\nfirst label: label1\n------------------------------------------------------------------\nuuidmsg: 4ce47c5c-60d2-4f78-810f-ac730136f462\ncount of labels: 2\nfirst label: label1\n------------------------------------------------------------------\nuuidmsg: 5e139007-9eea-4e71-9c5a-44f08c93027e\ncount of labels: 2\nfirst label: label1\n------------------------------------------------------------------\nuuidmsg: 67138174-08a9-4943-848a-736bddd755b9\ncount of labels: 2\nfirst label: label1\n------------------------------------------------------------------\nuuidmsg: 6956ea01-b834-461f-85cf-5621e04f02fb\ncount of labels: 2\nfirst label: label1\n------------------------------------------------------------------\nuuidmsg: 6c9ca46b-84fb-40d2-8523-2ad07284a43c\ncount of labels: 2\nfirst label: label1\n------------------------------------------------------------------\nuuidmsg: 708be3d8-7ddb-4ef5-9b00-37021b7b83ff\ncount of labels: 2\nfirst label: label1\n------------------------------------------------------------------\nuuidmsg: c10eff49-4412-425d-99ef-d8b3f95c3806\ncount of labels: 2\nfirst label: label1\n------------------------------------------------------------------\nuuidmsg: feddb62d-fdfa-494a-8e4a-e1b2209134a6\ncount of labels: 2\nfirst label: label1\n------------------------------------------------------------------\n</code></pre> <p>Source: examples/python/gRPC/images/gRPC_pb_queryImage.py</p> <pre><code>#!/usr/bin/env python3\n# NOTE: This file is referenced in the following mkdocs files:\n#   images.md\n# Any changes done in here will be reflected in there\nimport sys\nfrom typing import List, Optional\n\nfrom google.protobuf import empty_pb2\nfrom grpc import Channel\nfrom seerep.pb import image_pb2 as image\nfrom seerep.pb import image_service_pb2_grpc as imageService\nfrom seerep.pb import label_category_pb2, label_pb2\nfrom seerep.pb import meta_operations_pb2_grpc as metaOperations\nfrom seerep.pb import point2d_pb2 as point2d\nfrom seerep.pb import query_pb2 as query\nfrom seerep.util.common import get_gRPC_channel\n\n\ndef query_images(\n    target_project_uuid: Optional[str] = None,\n    grpc_channel: Channel = get_gRPC_channel(),\n) -&gt; List[image.Image]:\n    # 1. Get gRPC service objects\n    stub = imageService.ImageServiceStub(grpc_channel)\n    stubMeta = metaOperations.MetaOperationsStub(grpc_channel)\n\n    # 3. Check if we have an existing test project, if not, we stop here\n    if target_project_uuid is None:\n        # 2. Get all projects from the server\n        response = stubMeta.GetProjects(empty_pb2.Empty())\n        for project in response.projects:\n            print(project.name + \" \" + project.uuid + \"\\n\")\n            if project.name == \"testproject\":\n                target_project_uuid = project.uuid\n\n        if target_project_uuid is None:\n            print(\"\"\"\n                No project with name 'testproject' found! Execute\n                gRPC_pb_sendLabeledImage.py beforehand!\n            \"\"\")\n            sys.exit()\n\n    # 4. Create a query with parameters\n    theQuery = query.Query()\n    theQuery.projectuuid.append(target_project_uuid)\n\n    theQuery.polygon.z = -200\n    theQuery.polygon.height = 800\n\n    theQuery.inMapFrame = True\n\n    scale = 150\n    vertices = [\n        point2d.Point2D(x=x, y=y)\n        for x, y in [\n            (-scale, -scale),\n            (-scale, scale),\n            (scale, scale),\n            (scale, -scale),\n        ]\n    ]\n    theQuery.polygon.vertices.extend(vertices)\n\n    # since epoche\n    theQuery.timeinterval.time_min.seconds = 1638549273\n    theQuery.timeinterval.time_min.nanos = 0\n    theQuery.timeinterval.time_max.seconds = 1938549273\n    theQuery.timeinterval.time_max.nanos = 0\n\n    # labels\n    labelsCategory = label_category_pb2.LabelCategory()\n    labelsCategory.category = \"category A\"\n    label = label_pb2.Label()\n    label.label = \"label1\"\n    labelsCategory.labels.append(label)\n    theQuery.labelCategory.append(labelsCategory)\n\n    # theQuery.inMapFrame = True\n    theQuery.fullyEncapsulated = False\n\n    # 5. Query the server for images matching the query and return them\n    return list(stub.GetImage(theQuery))\n\n\nif __name__ == \"__main__\":\n    queried_imgs = query_images()\n    print(f\"count of images {len(queried_imgs)}\")\n    for img in queried_imgs:\n        print(\n            f\"uuidmsg: {img.header.uuid_msgs}\"\n            + \"\\n\"\n            + f\"first label: {img.labels[0].labels[0].label}\"\n        )\n</code></pre> <p>After sending the images, executing the query script results in the following output:</p> <pre><code>count of images 8\nuuidmsg: 111e62dd-9aba-4fde-ae3d-ed3e3b6041f8\nfirst label: label1\nuuidmsg: 261a7b2c-297b-42db-93da-770e5f7f53cf\nfirst label: label1\nuuidmsg: 5e139007-9eea-4e71-9c5a-44f08c93027e\nfirst label: label1\nuuidmsg: 67138174-08a9-4943-848a-736bddd755b9\nfirst label: label1\nuuidmsg: 6956ea01-b834-461f-85cf-5621e04f02fb\nfirst label: label1\nuuidmsg: 708be3d8-7ddb-4ef5-9b00-37021b7b83ff\nfirst label: label1\nuuidmsg: c10eff49-4412-425d-99ef-d8b3f95c3806\nfirst label: label1\nuuidmsg: feddb62d-fdfa-494a-8e4a-e1b2209134a6\nfirst label: label1\n</code></pre>"},{"location":"tutorials/overview/","title":"Tutorials Overviews","text":"<p>The tutorials provide a starting point on how you can use SEEREP. Currently, the following topics are covered:</p> <ul> <li>Creating and retrieving projects</li> <li>Sending and querying images</li> <li>Writing python examples</li> <li>Writing python integration tests</li> </ul> <p>Before running any of the tutorials, make sure that you have a  running SEEREP instance available.</p> <p>If you're not familiar with flatbuffers, it is highly recommended to look at the tutorial first. Click on the python radio button to see the language specific tutorial.</p>"},{"location":"tutorials/overview/#local-instance","title":"Local Instance","text":"<p>To start SEEREP locally use <code>STRG+SHIFT+D</code> to open the Run &amp; Debug Menu in Vs-Code, select <code>seerep server</code> and press run. Now a terminal should open and print the following info messages:</p> <pre><code>[2024-07-16 14:41:27.416289]&lt;info&gt;: Initialized logging\n[2024-07-16 14:41:27.416806]&lt;info&gt;: The used logging folder is: /seerep/seerep-data/debug/log/\n[2024-07-16 14:41:27.416847]&lt;info&gt;: Current timezone: CET\n[2024-07-16 14:41:27.416879]&lt;info&gt;: SEEREP version: v0.2.7-25-g48531131\n[2024-07-16 14:41:27.416918]&lt;info&gt;: The used data folder is: /seerep/seerep-data/debug/\n[2024-07-16 14:41:27.417739]&lt;info&gt;: Addded Protocol Buffers gRPC services\n[2024-07-16 14:41:27.418177]&lt;info&gt;: Added Flatbuffers gRPC services\n[2024-07-16 14:41:27.423797]&lt;info&gt;: Serving gRPC Server on \"[::]:9090\"\n</code></pre>"},{"location":"tutorials/projects/","title":"Creating &amp; Retrieving Projects","text":""},{"location":"tutorials/projects/#creating-new-projects","title":"Creating new projects","text":"<p>New projects for new data can be created in the following way:</p> <p>Source: examples/gRPC/meta/gRPC_pb_createProject.py</p> <pre><code>#!/usr/bin/env python3\n# NOTE: This file is referenced in the following mkdocs files:\n#   projects.md\n# Any changes done in here will be reflected in there\nfrom typing import Tuple\n\nfrom grpc import Channel\nfrom seerep.pb import meta_operations_pb2_grpc as metaOperations\nfrom seerep.pb import projectCreation_pb2\nfrom seerep.util.common import get_gRPC_channel\n\n\ndef create_project(\n    grpc_channel: Channel = get_gRPC_channel(),\n) -&gt; Tuple[str, str]:\n    stub = metaOperations.MetaOperationsStub(grpc_channel)\n    response = stub.CreateProject(\n        projectCreation_pb2.ProjectCreation(\n            name=\"testproject\", mapFrameId=\"map\"\n        )\n    )\n\n    return response.name, response.uuid\n\n\nif __name__ == \"__main__\":\n    ret = create_project()\n    print(\"The new project on the server is (name/uuid):\")\n    print(\"\\t\" + ret[0] + \" \" + ret[1])\n</code></pre> <p>Output:</p> <pre><code>The new project on the server is (name/uuid):\n        testproject ff739be8-cf0c-4657-bff0-f66f3e7f578d\n</code></pre>"},{"location":"tutorials/projects/#retrieving-projects","title":"Retrieving projects","text":"<p>After we created two projects, we can query them. Currently the name doesn't have to be unique.</p> FlatbuffersProtocol Buffers <p>Source: examples/gRPC/meta/gRPC_fb_getProjects.py</p> <pre><code>#!/usr/bin/env python3\n# NOTE: This file is referenced in the following mkdocs files:\n#   projects.md\n# Any changes done in here will be reflected in there\nfrom typing import List\n\nimport flatbuffers\nfrom grpc import Channel\nfrom seerep.fb import Empty, ProjectInfo, ProjectInfos\nfrom seerep.fb import meta_operations_grpc_fb as metaOperations\nfrom seerep.util.common import get_gRPC_channel\n\n\ndef get_projects_raw(\n    grpc_channel: Channel = get_gRPC_channel(),\n) -&gt; bytearray:\n    \"\"\"\n    Returns: bytearray of type ProjectInfos\n    \"\"\"\n    stub = metaOperations.MetaOperationsStub(grpc_channel)\n\n    builder = flatbuffers.Builder(1024)\n    Empty.Start(builder)\n    emptyMsg = Empty.End(builder)\n    builder.Finish(emptyMsg)\n    buf = builder.Output()\n\n    responseBuf = stub.GetProjects(bytes(buf))\n    return responseBuf\n\n\ndef get_projects(\n    grpc_channel: Channel = get_gRPC_channel(),\n) -&gt; ProjectInfos.ProjectInfos:\n    return ProjectInfos.ProjectInfos.GetRootAs(get_projects_raw(grpc_channel))\n\n\nif __name__ == \"__main__\":\n    response = get_projects()\n\n    projects_list: List[ProjectInfo.ProjectInfo] = []\n\n    for i in range(response.ProjectsLength()):\n        projects_list.append(response.Projects(i))\n\n    print(\"The server has the following projects (name/uuid):\")\n    for project in projects_list:\n        print(\n            \"\\t\"\n            + project.Name().decode(\"utf-8\")\n            + \" \"\n            + project.Uuid().decode(\"utf-8\")\n        )\n</code></pre> <p>Output:</p> <pre><code>The server has the following projects (name/uuid):\n    testproject 842de425-2d50-4adf-8aa3-6df257a7c76c\n    testproject ff739be8-cf0c-4657-bff0-f66f3e7f578d\n</code></pre> <p>Source: examples/gRPC/meta/gRPC_pb_getProjects.py</p> <pre><code>#!/usr/bin/env python3\n# NOTE: This file is referenced in the following mkdocs files:\n#   projects.md\n# Any changes done in here will be reflected in there\nfrom typing import List, Tuple\n\nfrom google.protobuf import empty_pb2\nfrom grpc import Channel\nfrom seerep.pb import meta_operations_pb2_grpc as metaOperations\nfrom seerep.util.common import get_gRPC_channel\n\n\ndef get_projects(\n    grpc_channel: Channel = get_gRPC_channel(),\n) -&gt; List[Tuple[str, str]]:\n    stub = metaOperations.MetaOperationsStub(grpc_channel)\n\n    response = stub.GetProjects(empty_pb2.Empty())\n\n    projects_list: List[Tuple[str, str]] = []\n    print(\"The server has the following projects (name/uuid):\")\n\n    for projectinfo in response.projects:\n        projects_list.append((projectinfo.name, projectinfo.uuid))\n\n    return projects_list\n\n\nif __name__ == \"__main__\":\n    project_list = get_projects()\n    for proj in project_list:\n        print(\"\\t\" + proj[0] + \" \" + proj[1])\n</code></pre> <p>Output:</p> <pre><code>The server has the following projects (name/uuid):\n    testproject 842de425-2d50-4adf-8aa3-6df257a7c76c\n    testproject ff739be8-cf0c-4657-bff0-f66f3e7f578d\n</code></pre>"},{"location":"tutorials/writing-python-examples/","title":"Writing examples for the SEEREP API","text":"<p>To write a example it is a good idea to refer to already written ones. The focus in this documentation lies on flatbuffers type messages, because of the potential deprecation of protobuf in the project. All protobuf functionality can be replicated using flatbuffers, and flatbuffers should be used instead.</p> <p>In this case the example gRPC_fb_addLabel.py will be reviewed. Service type definitions for all available flatbuffers type services can be found here. Type definitions of all flatbuffers types can be found here.</p>"},{"location":"tutorials/writing-python-examples/#the-code","title":"The code","text":"<pre><code>import sys\nimport uuid\nfrom typing import List, Optional, Tuple\n\nimport flatbuffers\nfrom grpc import Channel\nfrom seerep.fb import DatasetUuidLabel, Image, ProjectInfos\nfrom seerep.fb import image_service_grpc_fb as imageService\nfrom seerep.fb import meta_operations_grpc_fb as meta_ops\nfrom seerep.util.common import get_gRPC_channel\nfrom seerep.util.fb_helper import (\n    create_dataset_uuid_label,\n    create_label,\n    create_label_category,\n    createEmpty,\n    createQuery,\n)\n</code></pre> <p>First some of the modules to interact with the servers services will be highlighted. <code>seerep.fb</code> contains all python interfaces for the SEEREP services as well as the Message types. sereep.util.fb_helper contains helper functions related to flatbuffers, for instance functions to create a message type directly.</p>"},{"location":"tutorials/writing-python-examples/#interaction-with-seerep-services-and-handling-the-data","title":"Interaction with SEEREP services and handling the data","text":"<pre><code>def add_label_raw(\n    target_proj_uuid: Optional[str] = None,\n    grpc_channel: Channel = get_gRPC_channel(),\n) -&gt; List[Tuple[str, bytearray]]:\n</code></pre> <p>The interaction functionality is contained within this function. With the function definition, an option should be given to specify a target project, if the message type allows setting it. Additionally the <code>grpc_channel</code> should be a parameter in order to be able to target servers other than <code>localhost:9090</code>. Both options are useful for testing later. More parameters can be added optionally, if needed for the test cases.</p> <pre><code>    stubMeta = meta_ops.MetaOperationsStub(grpc_channel)\n\n    # 3. Check if we have an existing test project, if not, one is created.\n    if target_proj_uuid is None:\n        # 2. Get all projects from the server\n        response = ProjectInfos.ProjectInfos.GetRootAs(\n            stubMeta.GetProjects(bytes(createEmpty(flatbuffers.Builder(1024))))\n        )\n        for i in range(response.ProjectsLength()):\n            proj_name = response.Projects(i).Name().decode()\n            proj_uuid = response.Projects(i).Uuid().decode()\n            print(proj_name + \" \" + proj_uuid)\n            if proj_name == \"testproject\":\n                target_proj_uuid = proj_uuid\n\n        if target_proj_uuid is None:\n            print(\"\"\"\n                Please create a project with labeled images using\n                gRPC_pb_sendLabeledImage.py first.\"\n            \"\"\")\n            sys.exit()\n</code></pre> <p>At first, if <code>target_proj_uuid</code> is not set, the <code>MetaOperationsStub</code> utilizing flatbuffers gRPC communication with the SEEREP server is used to retrieve a list of all available projects of that server (specifically in the form of project_infos.fbs ) and <code>target_proj_uuid</code> is set to the uuid of the first project with the name <code>testproject</code> on that list.</p> <pre><code>    stub = imageService.ImageServiceStub(grpc_channel)\n\n    builder = flatbuffers.Builder(1024)\n    query = createQuery(\n        builder,\n        projectUuids=[builder.CreateString(target_proj_uuid)],\n        withoutData=True,\n    )\n    builder.Finish(query)\n    buf = builder.Output()\n\n    response_ls: List = list(stub.GetImage(bytes(buf)))\n    if not response_ls:\n        print(\"\"\"\n            No images found. Please create a project with labeled images\n            using gRPC_pb_sendLabeledImage.py first.\n        \"\"\")\n        sys.exit()\n</code></pre> <p>Following on the code requests all images from the project with the <code>uuid</code> of <code>target_proj_uuid</code> using the <code>ImageServiceStub</code>. The service definition looks as follows:</p> <pre><code>include \"image.fbs\";\ninclude \"query.fbs\";\ninclude \"label_category.fbs\";\ninclude \"dataset_uuid_label.fbs\";\n\ninclude \"server_response.fbs\";\n\nnamespace seerep.fb;\n\nrpc_service ImageService {\n  GetImage(seerep.fb.Query):seerep.fb.Image (streaming: \"server\");\n  TransferImage(seerep.fb.Image):seerep.fb.ServerResponse  (streaming: \"client\");\n  AddLabels(seerep.fb.DatasetUuidLabel):seerep.fb.ServerResponse   (streaming: \"client\");\n}\n</code></pre> <p><code>GetImage()</code> takes a argument of type seerep.fb.Query, a more generic build query type for use in various services in SEEREP, in it's serialized form and returns data of type seerep.fb.Image from the server.</p> <pre><code>    msgToSend = []\n    label_list: List[Tuple[str, bytearray]] = []\n\n    for responseBuf in response_ls:\n        response = Image.Image.GetRootAs(responseBuf)\n\n        img_uuid = response.Header().UuidMsgs().decode(\"utf-8\")\n        projectUuid = response.Header().UuidProject().decode(\"utf-8\")\n\n        labelStr = [\"label1\", \"label2\"]\n        labels = []\n\n        for labelAct in labelStr:\n            labels.append(\n                create_label(\n                    builder=builder,\n                    label=labelAct,\n                    label_id=1,\n                    instance_uuid=str(uuid.uuid4()),\n                    instance_id=2,\n                )\n            )\n        labelsCategory = []\n        labelsCategory.append(\n            create_label_category(\n                builder=builder,\n                labels=labels,\n                datumaro_json=\"a very valid datumaro json\",\n                category=\"laterAddedLabel\",\n            )\n        )\n\n        dataset_uuid_label = create_dataset_uuid_label(\n            builder=builder,\n            projectUuid=projectUuid,\n            datasetUuid=img_uuid,\n            labels=labelsCategory,\n        )\n\n        builder.Finish(dataset_uuid_label)\n        buf = builder.Output()\n\n        label_list.append(\n            (\n                img_uuid,\n                buf,\n            )\n        )\n\n        msgToSend.append(bytes(buf))\n</code></pre> <p>This code builds a list of DatasetUuidLabel adding some sample data into the components of each Label Category. At the beginning two lists are defined <code>msgToSend</code> is a list containing the serialized labels and <code>label_list</code> is a list containing mappings where each image uuid is mapped to it's added labels. After that the returned images from the query before are iterated. Next Label are created and their joint <code>header</code> uuids are set to the appropriate <code>project_uuid</code> and <code>msg_uuid</code> to match that specific image. At the end the Labels are serialized and added to the lists.</p> <p>The type definition of LabelCategory looks as follows:</p> <pre><code>include \"label.fbs\";\n\nnamespace seerep.fb;\n\ntable LabelCategory {\n  category:string;\n  labels:[Label];\n  datumaroJson:string;\n}\n\nroot_type LabelCategory;\n</code></pre> <p>And the type definition of Label looks as follows:</p> <pre><code>namespace seerep.fb;\n\ntable Label {\n  label:string;\n  labelIdDatumaro:int;\n  instanceUuid:string;\n  instanceIdDatumaro:int;\n}\n\nroot_type Label;\n</code></pre> <pre><code>        buf = builder.Output()\n</code></pre> <p>Lastly the service is called, the LabelCategory are send to the SEEREP server and the list with the mappings is returned for further use. Note that the flatbuffers objects are not returned in their deserialized state as the function <code>fb_flatc_dict</code> defined in here makes use of that state.</p>"},{"location":"tutorials/writing-python-examples/#wrapping-the-raw-function","title":"Wrapping the raw function","text":"<pre><code>def add_label(\n    target_proj_uuid: Optional[str] = None,\n    grpc_channel: Channel = get_gRPC_channel(),\n) -&gt; List[Tuple[str, DatasetUuidLabel.DatasetUuidLabel]]:\n    return [\n        (img_uuid, DatasetUuidLabel.DatasetUuidLabel.GetRootAs(labelbuf))\n        for img_uuid, labelbuf in add_label_raw(target_proj_uuid, grpc_channel)\n    ]\n</code></pre> <p>This function is essentially just a wrapper for <code>add_bb_raw()</code> to return the deserialized objects to be accessed through their regular flatbuffers interfaces (in this case of type <code>DatasetUuidLabel.DatasetUuidLabel</code>).</p>"},{"location":"tutorials/writing-python-examples/#allow-for-independent-execution-of-the-script","title":"Allow for independent execution of the script","text":"<pre><code>if __name__ == \"__main__\":\n    label_list = add_label()\n    for img_uuid, labelAllCat in label_list:\n        print(f\"Added label to image with uuid {img_uuid}:\")\n        for labelCategory in labelAllCat.Labels():\n            for label in labelCategory.Labels():\n                print(f\"uuid: {label.Label().decode()}\")\n</code></pre> <p>The last part can execute the script independently and targets the server at the default address, which is <code>localhost:9090</code>. On successful execution a subset of the sent data based on the returned mapping is printed.</p>"},{"location":"tutorials/writing-python-examples/#some-important-considerations","title":"Some important considerations","text":"<p>To conclude for most of the examples it is best practice to follow this structure, namely first having a function which returns the serialized data, then wrapping that function to return the deserialized variant and at the end the <code>if __name__ == \"__main__\"</code> part of the script, such that the script can be executed independently. Of course functionality can be outsourced into other functions, when it makes sense. This structure eases the process of writing tests later on (see writing-tests.md), especially when <code>fb_flatc_dict</code> should be utilized.</p>"},{"location":"tutorials/writing-python-tests/","title":"Writing integration tests for example pyscripts","text":"<p>Before a test is written it makes sense to understand how a example is structured. For this see writing-examples.md as a introduction. How tests can be structured will be demonstrated on the already created <code>test_ gRPC_fb_addLabels</code> test found here.</p> <p>As the testing framework for python pytest is used.</p>"},{"location":"tutorials/writing-python-tests/#the-code","title":"The code","text":"<pre><code>from typing import List\n\nimport flatbuffers\nfrom grpc import Channel\nfrom gRPC.images import gRPC_fb_addLabel as add_label\nfrom gRPC.images import gRPC_pb_sendLabeledImage as add_img\nfrom seerep.fb import image_service_grpc_fb as imageService\nfrom seerep.util.fb_helper import createQuery\nfrom seerep.util.fb_to_dict import SchemaFileNames, fb_flatc_dict\n</code></pre> <p>For the imported modules, note that the examples themselves are imported to be used in the tests. Furthermore helper functions from <code>seerep.util.fb_helper</code>, as well as <code>fb_flatc_dict</code> are imported.</p> <pre><code>def get_imgs(target_proj_uuid: str, grpc_channel: Channel) -&gt; List:\n    builder = flatbuffers.Builder(1024)\n    stub = imageService.ImageServiceStub(grpc_channel)\n    query = createQuery(\n        builder,\n        projectUuids=[builder.CreateString(target_proj_uuid)],\n        withoutData=True,\n    )\n    builder.Finish(query)\n    buf = builder.Output()\n    response_ls: List = list(stub.GetImage(bytes(buf)))\n\n    return [fb_flatc_dict(buf, SchemaFileNames.IMAGE) for buf in response_ls]\n</code></pre> <p>This is a helper function to retrieve all images the targeted project on the targeted server has. At the end with the service call <code>GetImage()</code> the images are returned in a list of bytearray objects, which on the return line are converted to a python dictionary with the help of the <code>SchemaFileNames</code> enum. <code>SchemaFileNames</code> contains references to the file names of the datatypes of all the SEEREP flatbuffers types, this is required for the <code>flatc</code> compiler to know how to decode the object.</p> <pre><code>def test_addLabel(grpc_channel, project_setup):\n    _, proj_uuid = project_setup\n\n    # send labeled images to the server for preparation\n    add_img.send_labeled_images(\n        target_proj_uuid=proj_uuid, grpc_channel=grpc_channel\n    )\n\n    sent_label = add_label.add_label_raw(\n        target_proj_uuid=proj_uuid, grpc_channel=grpc_channel\n    )\n\n    assert sent_label is not None\n\n    # use a regular query to query the images from the server to check if the\n    # label is the same\n    all_imgs = get_imgs(proj_uuid, grpc_channel)\n\n    for label_img_uuid, label_img in sent_label:\n        img_label = [\n            img\n            for img in all_imgs\n            if img[\"header\"][\"uuid_msgs\"] == label_img_uuid\n        ][0]\n\n        # iterate through all categories of the image\n        filtered_label = [\n            label\n            for label in img_label[\"labels\"]\n            if label[\"category\"] == \"laterAddedLabel\"\n        ]\n\n        sent_labels = fb_flatc_dict(\n            label_img, SchemaFileNames.DATASET_UUID_LABEL\n        )[\"labels\"]\n\n        assert len(filtered_label) == len(sent_labels)\n\n        for label_cat in filtered_label:\n            assert label_cat in sent_labels\n</code></pre> <p>Next up the test function is defined and uses the fixture <code>grpc_channel</code>, which spins the test server up, creates a channel to that server and makes sure that the server is terminated after testing is done. The fixture <code>project_setup</code> creates a test project on the server and deletes that after the testing function using SEEREP server calls. Implementations of both fixtures can be found here.</p> <p>After that the <code>project_uuid</code> of the created project is retrieved and used for the different calls to the example functions. To attach new Labels to images, it has to be ensured that images are present. This is done by utilizing the gRPC_pb_sendLabeledImage example. Then the Labels example can be used to add Labels to those images.</p> <p>Following on the Labels returned by <code>add_label_raw()</code> are tested and compared against those now persisting on the server. <code>get_imgs</code> retrieves all the images from the server, each mapping of image <code>uuid</code> to Labels is iterated and in the list of all images the image, which matches the image <code>uuid</code> of the mapping, is inspected further. Only the Labels with the category <code>laterAddedBB</code> are relevant and therefore filtered. Lastly the sent Labels are converted to python dictionaries and compared for matching with the filtered image attached Labels.</p>"},{"location":"tutorials/writing-python-tests/#tips-to-ease-development","title":"Tips to ease development","text":"<ul> <li><code>fb_flatc_dict()</code> in conjunction with <code>pytest -s</code> command is a good option for debugging tests, as the dictionary and therefore the objects data contents can be printed that way.</li> <li>If a recursive operation has to be applied to a dictionary <code>boltons</code> remap() function can be used, like in test_gRPC_fb_createGeodeticCoordProject.py.</li> <li>If a test should contain a lot of variations in the components of a datatype a look here could simplify things</li> </ul>"}]}